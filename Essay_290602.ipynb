{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YIlFUk0puRY9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean, std\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.metrics import classification_report\n",
    "import itertools\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, make_scorer\n",
    "kappa_scorer = make_scorer(cohen_kappa_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "O8IflLV95O1X"
   },
   "outputs": [],
   "source": [
    "# Load data from Url\n",
    "url = 'https://drive.google.com/uc?id=1ImrEW5T3cOdecopkVNd279XJ8Pifl9Ke'\n",
    "df = pd.read_csv(url)\n",
    "# One-hot encode the 'climate_class' categorical feature\n",
    "df_encoded = pd.get_dummies(df, columns=['climate_class'], prefix=['climate_class'], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>final_duration</th>\n",
       "      <th>final_cost</th>\n",
       "      <th>adjustment_cost</th>\n",
       "      <th>final_change_cost</th>\n",
       "      <th>delay_class</th>\n",
       "      <th>climate_class_C</th>\n",
       "      <th>climate_class_HD</th>\n",
       "      <th>climate_class_MR</th>\n",
       "      <th>climate_class_SA</th>\n",
       "      <th>climate_class_SMR</th>\n",
       "      <th>climate_class_VHD</th>\n",
       "      <th>climate_class_VHH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2837</td>\n",
       "      <td>7.178160e+11</td>\n",
       "      <td>4.632660e+11</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1765</td>\n",
       "      <td>2.525490e+11</td>\n",
       "      <td>4.755340e+11</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3311</td>\n",
       "      <td>9.573671e+10</td>\n",
       "      <td>3.285553e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1757</td>\n",
       "      <td>3.828944e+10</td>\n",
       "      <td>3.713023e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2577</td>\n",
       "      <td>1.042549e+10</td>\n",
       "      <td>3.080719e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>796</td>\n",
       "      <td>7.308602e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.308602e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>1456</td>\n",
       "      <td>7.437125e+09</td>\n",
       "      <td>3.319195e+09</td>\n",
       "      <td>7.519285e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>1087</td>\n",
       "      <td>5.139000e+09</td>\n",
       "      <td>1.862507e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>819</td>\n",
       "      <td>5.897179e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.943477e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>694</td>\n",
       "      <td>4.858939e+09</td>\n",
       "      <td>7.102244e+08</td>\n",
       "      <td>4.858939e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     final_duration    final_cost  adjustment_cost  final_change_cost  \\\n",
       "0              2837  7.178160e+11     4.632660e+11       0.000000e+00   \n",
       "1              1765  2.525490e+11     4.755340e+11       0.000000e+00   \n",
       "2              3311  9.573671e+10     3.285553e+10       0.000000e+00   \n",
       "3              1757  3.828944e+10     3.713023e+10       0.000000e+00   \n",
       "4              2577  1.042549e+10     3.080719e+09       0.000000e+00   \n",
       "..              ...           ...              ...                ...   \n",
       "238             796  7.308602e+09     0.000000e+00       7.308602e+09   \n",
       "239            1456  7.437125e+09     3.319195e+09       7.519285e+09   \n",
       "240            1087  5.139000e+09     1.862507e+09       0.000000e+00   \n",
       "241             819  5.897179e+09     0.000000e+00       5.943477e+09   \n",
       "242             694  4.858939e+09     7.102244e+08       4.858939e+09   \n",
       "\n",
       "     delay_class  climate_class_C  climate_class_HD  climate_class_MR  \\\n",
       "0              2            False             False             False   \n",
       "1              2            False             False             False   \n",
       "2              2            False             False             False   \n",
       "3              2            False             False             False   \n",
       "4              2            False             False             False   \n",
       "..           ...              ...               ...               ...   \n",
       "238            2             True             False             False   \n",
       "239            2            False              True             False   \n",
       "240            2             True             False             False   \n",
       "241            2             True             False             False   \n",
       "242            2             True             False             False   \n",
       "\n",
       "     climate_class_SA  climate_class_SMR  climate_class_VHD  climate_class_VHH  \n",
       "0               False              False               True              False  \n",
       "1               False              False               True              False  \n",
       "2               False              False               True              False  \n",
       "3               False              False               True              False  \n",
       "4               False              False               True              False  \n",
       "..                ...                ...                ...                ...  \n",
       "238             False              False              False              False  \n",
       "239             False              False              False              False  \n",
       "240             False              False              False              False  \n",
       "241             False              False              False              False  \n",
       "242             False              False              False              False  \n",
       "\n",
       "[243 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5gGGocu-GNgy"
   },
   "outputs": [],
   "source": [
    "# Define the condition\n",
    "condition = df_encoded['delay_class'] < 2\n",
    "\n",
    "# Filter rows that meet the condition\n",
    "filtered_df = df_encoded[condition]\n",
    "\n",
    "# Duplicate the filtered rows (you can change the number of times to duplicate)\n",
    "num_duplicates = 2  # Change this to the desired number of duplicates\n",
    "duplicated_df = pd.concat([filtered_df] * num_duplicates, ignore_index=True)\n",
    "\n",
    "# Concatenate the original DataFrame with the duplicated DataFrame\n",
    "filtered_df = pd.concat([df_encoded, duplicated_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VbOAxvAnCS6a",
    "outputId": "1b469786-371b-4c25-8588-0e80cc9841c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sep\\AppData\\Local\\Temp\\ipykernel_12344\\1544043725.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[['final_duration', 'final_cost', 'adjustment_cost', 'final_change_cost']] = scaler.fit_transform(X[['final_duration', 'final_cost', 'adjustment_cost', 'final_change_cost']])\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "X = filtered_df[['final_duration', 'final_cost', 'adjustment_cost', 'final_change_cost','climate_class_C', 'climate_class_HD', 'climate_class_MR', 'climate_class_SA', 'climate_class_SMR', 'climate_class_VHD', 'climate_class_VHH']]\n",
    "y = filtered_df['delay_class']\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "X[['final_duration', 'final_cost', 'adjustment_cost', 'final_change_cost']] = scaler.fit_transform(X[['final_duration', 'final_cost', 'adjustment_cost', 'final_change_cost']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "wObj7tPZ5OdR",
    "outputId": "dd845981-f055-41fc-c8d9-7a8e6428e279"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>final_duration</th>\n",
       "      <th>final_cost</th>\n",
       "      <th>adjustment_cost</th>\n",
       "      <th>final_change_cost</th>\n",
       "      <th>delay_class</th>\n",
       "      <th>climate_class_C</th>\n",
       "      <th>climate_class_HD</th>\n",
       "      <th>climate_class_MR</th>\n",
       "      <th>climate_class_SA</th>\n",
       "      <th>climate_class_SMR</th>\n",
       "      <th>climate_class_VHD</th>\n",
       "      <th>climate_class_VHH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2837</td>\n",
       "      <td>7.178160e+11</td>\n",
       "      <td>4.632660e+11</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1765</td>\n",
       "      <td>2.525490e+11</td>\n",
       "      <td>4.755340e+11</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3311</td>\n",
       "      <td>9.573671e+10</td>\n",
       "      <td>3.285553e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1757</td>\n",
       "      <td>3.828944e+10</td>\n",
       "      <td>3.713023e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2577</td>\n",
       "      <td>1.042549e+10</td>\n",
       "      <td>3.080719e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>849</td>\n",
       "      <td>1.506803e+10</td>\n",
       "      <td>5.336830e+09</td>\n",
       "      <td>1.775818e+10</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>1042</td>\n",
       "      <td>1.715261e+10</td>\n",
       "      <td>6.346088e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>161</td>\n",
       "      <td>1.572668e+10</td>\n",
       "      <td>1.888369e+08</td>\n",
       "      <td>1.590530e+10</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>597</td>\n",
       "      <td>2.706334e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.677253e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>468</td>\n",
       "      <td>5.666477e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.666477e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>439 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     final_duration    final_cost  adjustment_cost  final_change_cost  \\\n",
       "0              2837  7.178160e+11     4.632660e+11       0.000000e+00   \n",
       "1              1765  2.525490e+11     4.755340e+11       0.000000e+00   \n",
       "2              3311  9.573671e+10     3.285553e+10       0.000000e+00   \n",
       "3              1757  3.828944e+10     3.713023e+10       0.000000e+00   \n",
       "4              2577  1.042549e+10     3.080719e+09       0.000000e+00   \n",
       "..              ...           ...              ...                ...   \n",
       "434             849  1.506803e+10     5.336830e+09       1.775818e+10   \n",
       "435            1042  1.715261e+10     6.346088e+09       0.000000e+00   \n",
       "436             161  1.572668e+10     1.888369e+08       1.590530e+10   \n",
       "437             597  2.706334e+09     0.000000e+00       2.677253e+09   \n",
       "438             468  5.666477e+09     0.000000e+00       5.666477e+09   \n",
       "\n",
       "     delay_class  climate_class_C  climate_class_HD  climate_class_MR  \\\n",
       "0              2            False             False             False   \n",
       "1              2            False             False             False   \n",
       "2              2            False             False             False   \n",
       "3              2            False             False             False   \n",
       "4              2            False             False             False   \n",
       "..           ...              ...               ...               ...   \n",
       "434            0             True             False             False   \n",
       "435            0             True             False             False   \n",
       "436            0            False             False             False   \n",
       "437            1            False             False             False   \n",
       "438            1            False             False             False   \n",
       "\n",
       "     climate_class_SA  climate_class_SMR  climate_class_VHD  climate_class_VHH  \n",
       "0               False              False               True              False  \n",
       "1               False              False               True              False  \n",
       "2               False              False               True              False  \n",
       "3               False              False               True              False  \n",
       "4               False              False               True              False  \n",
       "..                ...                ...                ...                ...  \n",
       "434             False              False              False              False  \n",
       "435             False              False              False              False  \n",
       "436             False              False               True              False  \n",
       "437             False              False               True              False  \n",
       "438             False              False               True              False  \n",
       "\n",
       "[439 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show data sample\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MRS7pVYxBG0i",
    "outputId": "01b38a94-6821-4373-f950-6bbbd444a886"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(439, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mrK0zH47ef2G"
   },
   "outputs": [],
   "source": [
    "# Apply outlier detection\n",
    "outlier_detector = EllipticEnvelope()\n",
    "outliers = outlier_detector.fit_predict(X[['final_duration', 'final_cost', 'adjustment_cost', 'final_change_cost', 'climate_class_C', 'climate_class_HD', 'climate_class_MR', 'climate_class_SA', 'climate_class_SMR', 'climate_class_VHD', 'climate_class_VHH']])\n",
    "X = X[outliers == 1]\n",
    "y = y[outliers == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "zQ9Hq-aLehkM"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "No11XbyMOpUE",
    "outputId": "91552993-778b-479a-e47e-18579763701a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(396, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOsRCVXrtUkH"
   },
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M3MUmeMoXEaF",
    "outputId": "232528f2-6666-4d75-fdc7-eccbeacf4724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.724174 using {'C': 100, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "kernel = ['linear','poly', 'rbf', 'sigmoid']\n",
    "C = [ 1.0, 2.0, 3.0, 5.0, 10.0, 0.1, 0.01, 100]\n",
    "grid = dict(kernel=kernel,C=C)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                           cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(X, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F1BrKhB0sGRN",
    "outputId": "513382be-4c1c-42ea-a94c-6905735b3be1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7329 (0.0301)\n",
      "f1_macro: 0.7299 (0.0302)\n",
      "precision_macro: 0.7439 (0.0294)\n",
      "recall_macro: 0.7335 (0.0299)\n",
      "kappa_scorer: 0.5995 (0.0450)\n"
     ]
    }
   ],
   "source": [
    "model_svm = SVC(C= 100, kernel='rbf')\n",
    "\n",
    "model=model_svm\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=1)\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 Score: 0.863607 using {'algorithm': 'auto', 'n_neighbors': 1, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "n_neighbors = range(1, 21)\n",
    "weights = ['uniform', 'distance']\n",
    "algorithm = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "grid = dict(n_neighbors=n_neighbors, weights=weights, algorithm=algorithm)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                           cv=cv, scoring='f1_macro', error_score=0)\n",
    "\n",
    "grid_result = grid_search.fit(X, y)\n",
    "print(\"Best F1 Score: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8662 (0.0305)\n",
      "f1_macro: 0.8590 (0.0337)\n",
      "precision_macro: 0.8833 (0.0319)\n",
      "recall_macro: 0.8663 (0.0304)\n",
      "kappa_scorer: 0.7993 (0.0456)\n"
     ]
    }
   ],
   "source": [
    "model_knn = KNeighborsClassifier(algorithm= 'auto', n_neighbors= 1, weights= 'uniform')\n",
    "model = model_knn\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=1)\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLEvQOp5tT5O"
   },
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m6kxJWLUdIWN",
    "outputId": "5f2c4059-6a7e-4859-a8b0-65056b81482b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.900766 using {'max_depth': 14, 'max_features': 'sqrt', 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=1)\n",
    "n_estimators = [50, 100, 120, 150, 200, 300]\n",
    "max_features = ['sqrt', 'log2', 0.5]\n",
    "max_depth = [2,6,8,10,12,14,16]\n",
    "grid = dict(n_estimators=n_estimators,\n",
    "            max_features=max_features,max_depth=max_depth)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                           cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(X, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vJ3cgJloHaiQ",
    "outputId": "b463c852-0802-44be-f17d-6a8d2d8e6a84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9101 (0.0370)\n",
      "f1_macro: 0.9070 (0.0389)\n",
      "precision_macro: 0.9225 (0.0304)\n",
      "recall_macro: 0.9102 (0.0367)\n",
      "kappa_scorer: 0.8652 (0.0554)\n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(random_state=1, max_depth=14 , max_features='sqrt', n_estimators=50)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "history = model_rf.fit(X_train,y_train)\n",
    "y_hat = model_rf.predict(X_test)\n",
    "\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=1)\n",
    "scores = cross_val_score(model_rf, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model_rf, X, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model_rf, X, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model_rf, X, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model_rf, X, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.872435 using {'max_depth': 14, 'max_features': 0.5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=1)\n",
    "max_features = ['sqrt', 'log2', 0.5]\n",
    "max_depth = [2,6,8,10,12,14,16]\n",
    "grid = dict(max_features=max_features,max_depth=max_depth)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                           cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(X, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8824 (0.0400)\n",
      "f1_macro: 0.8768 (0.0431)\n",
      "precision_macro: 0.8961 (0.0381)\n",
      "recall_macro: 0.8826 (0.0398)\n",
      "kappa_scorer: 0.8236 (0.0600)\n"
     ]
    }
   ],
   "source": [
    "model_dt = DecisionTreeClassifier(random_state=1, max_depth=16 , max_features=0.5)\n",
    "from sklearn.metrics import accuracy_score\n",
    "history = model_dt.fit(X_train,y_train)\n",
    "y_hat = model_dt.predict(X_test)\n",
    "\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=1)\n",
    "scores = cross_val_score(model_dt, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model_dt, X, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model_dt, X, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model_dt, X, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model_dt, X, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WmncurFTuN2U"
   },
   "source": [
    "# NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Amb4SOauQYg",
    "outputId": "d0f751dd-1d1a-4fd0-86d2-d1a70f36aae4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.418914 using {'var_smoothing': 0.005623413251903491}\n"
     ]
    }
   ],
   "source": [
    "model =  GaussianNB()\n",
    "var_smoothing= np.logspace(0,-9, num=5)\n",
    "grid = dict(var_smoothing=var_smoothing)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                           cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(X, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wt17LkrPucsD",
    "outputId": "767e3226-efb4-4783-dd24-2db445b11dd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4575 (0.0498)\n",
      "f1_macro: 0.4158 (0.0507)\n",
      "precision_macro: 0.4609 (0.0702)\n",
      "recall_macro: 0.4625 (0.0500)\n",
      "kappa_scorer: 0.1907 (0.0744)\n"
     ]
    }
   ],
   "source": [
    "model_nb = GaussianNB(var_smoothing= 1.0)\n",
    "\n",
    "model=model_nb\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=1)\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KD4p_3W93F8T"
   },
   "source": [
    "# Ann Shallow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cHzXgugQ3YOT",
    "outputId": "398271be-5470-407c-c785-198635147fdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.799191 using {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate': 'constant', 'solver': 'lbfgs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sep\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "# Tuning hyperparameters of shallow ANNs using grid search algorithm\n",
    "model = MLPClassifier(max_iter=1000,  random_state=1)\n",
    "hidden_layer_sizes= [(7),(8),(9),(10)]\n",
    "activation= ['tanh', 'relu','identity','logistic']\n",
    "solver= ['sgd', 'adam','lbfgs']\n",
    "alpha= [0.0001, 0.1, 0.5, 1, 0.7]\n",
    "learning_rate= ['constant','adaptive','invscaling']\n",
    "grid= dict(\n",
    "hidden_layer_sizes=hidden_layer_sizes,\n",
    "    activation=activation,\n",
    "    solver=solver,\n",
    "    alpha=alpha,\n",
    "    learning_rate=learning_rate)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                           cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(X, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tqxhb7EgYy6v",
    "outputId": "1ea04db1-f4bd-4d6e-f084-258fbc1312c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8061 (0.0497)\n",
      "f1_macro: 0.7990 (0.0514)\n",
      "precision_macro: 0.8187 (0.0519)\n",
      "recall_macro: 0.8062 (0.0500)\n",
      "kappa_scorer: 0.7091 (0.0748)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model_ann = MLPClassifier(max_iter=1000,random_state=1, activation= 'logistic', alpha= 0.0001, hidden_layer_sizes= (10), learning_rate= 'constant', solver= 'lbfgs' )\n",
    "\n",
    "model=model_ann\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=1)\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkCztnVMYzjs"
   },
   "source": [
    "# Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "DXa8H7iw4GxM",
    "outputId": "e4cd7e54-3438-4dd0-f51d-42bb0f5a5c55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.853434 using {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (9, 7), 'learning_rate': 'constant', 'solver': 'lbfgs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sep\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "# Finding the best architecture for proposed Deep-MLP-NN and Tuning its hyperparameters using grid search algorithm\n",
    "layer_2= []\n",
    "for a in range(7,10):\n",
    "    for b in range(7,10):\n",
    "        layer_2.append((a,b))\n",
    "#2layer\n",
    "model = MLPClassifier(max_iter=2000,  random_state=1)\n",
    "hidden_layer_sizes= layer_2\n",
    "activation= ['tanh', 'relu']\n",
    "solver= ['sgd', 'adam','lbfgs']\n",
    "alpha= [0.1, 1, 0.7]\n",
    "learning_rate= ['constant','adaptive','invscaling']\n",
    "grid= dict(\n",
    "hidden_layer_sizes=hidden_layer_sizes,\n",
    "    activation=activation,\n",
    "    solver=solver,\n",
    "    alpha=alpha,\n",
    "    learning_rate=learning_rate)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                           cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(X, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HelaPB7Bbjdy",
    "outputId": "2be0677a-05be-4598-95b2-0b557fb885c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8399 (0.0377)\n",
      "f1_macro: 0.8331 (0.0410)\n",
      "precision_macro: 0.8483 (0.0365)\n",
      "recall_macro: 0.8400 (0.0377)\n",
      "kappa_scorer: 0.7598 (0.0565)\n"
     ]
    }
   ],
   "source": [
    "model_mlp_2layer = MLPClassifier(max_iter=2000,random_state=1, activation= 'tanh', alpha= 0.1, hidden_layer_sizes= (9, 7), learning_rate= 'constant', solver= 'lbfgs' )\n",
    "\n",
    "model=model_mlp_2layer\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=1)\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vm3K-eDjBIMK"
   },
   "source": [
    "# Layer 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "KJ84BNTTBHfj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.864859 using {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (8, 8, 9), 'learning_rate': 'constant', 'solver': 'lbfgs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sep\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "layer_3= []\n",
    "for a in range(7,10):\n",
    "    for b in range(7,10):\n",
    "        for c in range(7,10):\n",
    "            layer_3.append((a,b,c))\n",
    "#3layer\n",
    "model = MLPClassifier(max_iter=2000,  random_state=1)\n",
    "hidden_layer_sizes= layer_3\n",
    "activation= ['tanh', 'relu']\n",
    "solver= ['adam','lbfgs']\n",
    "alpha= [0.1, 0.7]\n",
    "learning_rate= ['constant','adaptive']\n",
    "grid= dict(\n",
    "hidden_layer_sizes=hidden_layer_sizes,\n",
    "    activation=activation,\n",
    "    solver=solver,\n",
    "    alpha=alpha,\n",
    "    learning_rate=learning_rate)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                           cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(X, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "HqpvMyj7BPIA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8562 (0.0411)\n",
      "f1_macro: 0.8469 (0.0463)\n",
      "precision_macro: 0.8700 (0.0429)\n",
      "recall_macro: 0.8563 (0.0411)\n",
      "kappa_scorer: 0.7842 (0.0616)\n"
     ]
    }
   ],
   "source": [
    "model_mlp_3layer = MLPClassifier(max_iter=2000,random_state=1, activation= 'tanh', alpha= 0.1, hidden_layer_sizes= (8, 8, 9), learning_rate= 'constant', solver= 'lbfgs' )\n",
    "\n",
    "model=model_mlp_3layer\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=1)\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.870767 using {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (7, 9, 8, 9), 'learning_rate': 'constant', 'solver': 'lbfgs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sep\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "layer_4= []\n",
    "for a in range(7,10):\n",
    "    for b in range(7,10):\n",
    "        for c in range(7,10):\n",
    "            for d in range(7,10):\n",
    "                layer_4.append((a,b,c,d))\n",
    "#4layer\n",
    "model = MLPClassifier(max_iter=2000,  random_state=1)\n",
    "hidden_layer_sizes= layer_4\n",
    "activation= ['tanh', 'relu']\n",
    "solver= ['adam','lbfgs']\n",
    "alpha= [0.1, 0.7]\n",
    "learning_rate= ['constant','adaptive']\n",
    "grid= dict(\n",
    "hidden_layer_sizes=hidden_layer_sizes,\n",
    "    activation=activation,\n",
    "    solver=solver,\n",
    "    alpha=alpha,\n",
    "    learning_rate=learning_rate)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                           cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(X, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8632 (0.0405)\n",
      "f1_macro: 0.8563 (0.0437)\n",
      "precision_macro: 0.8799 (0.0383)\n",
      "recall_macro: 0.8635 (0.0401)\n",
      "kappa_scorer: 0.7947 (0.0607)\n"
     ]
    }
   ],
   "source": [
    "model_mlp_4layer = MLPClassifier(max_iter = 2000,\n",
    "                                 random_state = 1, \n",
    "                                 activation = 'tanh', \n",
    "                                 alpha = 0.1, \n",
    "                                 hidden_layer_sizes = (7, 9, 8, 9), \n",
    "                                 learning_rate = 'constant', \n",
    "                                 solver = 'lbfgs'\n",
    "                                )\n",
    "\n",
    "model=model_mlp_4layer\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=1)\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCwxwJ10bkew"
   },
   "source": [
    "# Layer 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "xEVM09oTa6fl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.867297 using {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (9, 8, 9, 9, 7), 'learning_rate': 'constant', 'solver': 'lbfgs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sep\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "layer_5= []\n",
    "for a in range(7,10):\n",
    "    for b in range(7,10):\n",
    "        for c in range(7,10):\n",
    "            for d in range(7,10):\n",
    "                 for e in range(7,10):\n",
    "                        layer_5.append((a,b,c,d,e))\n",
    "#5layer\n",
    "model = MLPClassifier(max_iter=2000,  random_state=1)\n",
    "hidden_layer_sizes= layer_5\n",
    "activation= ['tanh']\n",
    "solver= ['adam','lbfgs']\n",
    "alpha= [0.1]\n",
    "learning_rate= ['constant']\n",
    "grid= dict(\n",
    "hidden_layer_sizes=hidden_layer_sizes,\n",
    "    activation=activation,\n",
    "    solver=solver,\n",
    "    alpha=alpha,\n",
    "    learning_rate=learning_rate)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                           cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(X, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8425 (0.0414)\n",
      "f1_macro: 0.8323 (0.0458)\n",
      "precision_macro: 0.8609 (0.0426)\n",
      "recall_macro: 0.8426 (0.0412)\n",
      "kappa_scorer: 0.7637 (0.0621)\n"
     ]
    }
   ],
   "source": [
    "model_mlp_5layer = MLPClassifier(max_iter=2000,\n",
    "                                 random_state=1, \n",
    "                                 activation= 'tanh', \n",
    "                                 alpha= 0.1, \n",
    "                                 hidden_layer_sizes= (9, 8, 9, 9, 7), \n",
    "                                 learning_rate= 'constant', \n",
    "                                 solver= 'lbfgs' \n",
    "                                )\n",
    "\n",
    "model=model_mlp_5layer\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=1)\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.868773 using {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (8, 7, 7, 8, 8, 9), 'learning_rate': 'constant', 'solver': 'lbfgs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sep\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "layer_6= []\n",
    "for a in range(7,10):\n",
    "    for b in range(7,10):\n",
    "        for c in range(7,10):\n",
    "            for d in range(7,10):\n",
    "                 for e in range(7,10):\n",
    "                        for f in range(7,10):\n",
    "                            layer_6.append((a,b,c,d,e,f))\n",
    "#6layer\n",
    "model = MLPClassifier(max_iter=2000,  random_state=1)\n",
    "hidden_layer_sizes= layer_6\n",
    "activation= ['tanh']\n",
    "solver= ['lbfgs']\n",
    "alpha= [0.1]\n",
    "learning_rate= ['constant']\n",
    "grid= dict(\n",
    "hidden_layer_sizes=hidden_layer_sizes,\n",
    "    activation=activation,\n",
    "    solver=solver,\n",
    "    alpha=alpha,\n",
    "    learning_rate=learning_rate)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,\n",
    "                           cv=cv, scoring='f1_macro',error_score=0)\n",
    "grid_result = grid_search.fit(X, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8536 (0.0405)\n",
      "f1_macro: 0.8429 (0.0456)\n",
      "precision_macro: 0.8752 (0.0372)\n",
      "recall_macro: 0.8535 (0.0406)\n",
      "kappa_scorer: 0.7803 (0.0608)\n"
     ]
    }
   ],
   "source": [
    "model_mlp_6layer = MLPClassifier(max_iter=2000,\n",
    "                                 random_state=1, \n",
    "                                 activation= 'tanh', \n",
    "                                 alpha= 0.1, \n",
    "                                 hidden_layer_sizes= (8, 7, 7, 8, 8, 9), \n",
    "                                 learning_rate= 'constant', \n",
    "                                 solver= 'lbfgs' \n",
    "                                )\n",
    "\n",
    "model=model_mlp_6layer\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=1)\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9571 (0.0305)\n",
      "f1_macro: 0.9572 (0.0304)\n",
      "precision_macro: 0.9592 (0.0296)\n",
      "recall_macro: 0.9572 (0.0306)\n",
      "kappa_scorer: 0.9356 (0.0458)\n"
     ]
    }
   ],
   "source": [
    "# Select models with higher accuracy.\n",
    "base_models = [\n",
    "    #(\"svm\", model_svm),\n",
    "    (\"knn\", model_knn),\n",
    "    (\"rf\", model_rf),\n",
    "    (\"dt\", model_dt),\n",
    "    #(\"nb\", model_nb),\n",
    "    #(\"ann\", model_ann),\n",
    "    #(\"mlp_2layer\", model_mlp_2layer),\n",
    "    #(\"mlp_3layer\", model_mlp_3layer),\n",
    "    (\"mlp_4layer\", model_mlp_4layer),\n",
    "    #(\"mlp_5layer\", model_mlp_5layer),\n",
    "    #(\"mlp_6layer\", model_mlp_6layer),\n",
    "]\n",
    "\n",
    "# Define your meta-learner (you can choose any classifier)\n",
    "meta_learner = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Create the stacking ensemble\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_learner)\n",
    "model = stacking_model\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=1)\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9465 (0.0314)\n",
      "f1_macro: 0.9464 (0.0315)\n",
      "precision_macro: 0.9499 (0.0293)\n",
      "recall_macro: 0.9467 (0.0312)\n",
      "kappa_scorer: 0.9197 (0.0471)\n"
     ]
    }
   ],
   "source": [
    "# Select models with higher accuracy.\n",
    "base_models = [\n",
    "    #(\"svm\", model_svm),\n",
    "    (\"knn\", model_knn),\n",
    "    (\"rf\", model_rf),\n",
    "    (\"dt\", model_dt),\n",
    "    #(\"nb\", model_nb),\n",
    "    #(\"ann\", model_ann),\n",
    "    #(\"mlp_2layer\", model_mlp_2layer),\n",
    "    #(\"mlp_3layer\", model_mlp_3layer),\n",
    "    (\"mlp_4layer\", model_mlp_4layer),\n",
    "    #(\"mlp_5layer\", model_mlp_5layer),\n",
    "    #(\"mlp_6layer\", model_mlp_6layer),\n",
    "]\n",
    "\n",
    "# Define your meta-learner (you can choose any classifier)\n",
    "meta_learner = xgb.XGBClassifier(random_state=1)\n",
    "\n",
    "# Create the stacking ensemble\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_learner)\n",
    "model = stacking_model\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=1)\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9540 (0.0247)\n",
      "f1_macro: 0.9539 (0.0248)\n",
      "precision_macro: 0.9564 (0.0239)\n",
      "recall_macro: 0.9542 (0.0247)\n",
      "kappa_scorer: 0.9311 (0.0371)\n"
     ]
    }
   ],
   "source": [
    "# Select models with higher accuracy.\n",
    "base_models = [\n",
    "    #(\"svm\", model_svm),\n",
    "    (\"knn\", model_knn),\n",
    "    (\"rf\", model_rf),\n",
    "    (\"dt\", model_dt),\n",
    "    #(\"nb\", model_nb),\n",
    "    #(\"ann\", model_ann),\n",
    "    #(\"mlp_2layer\", model_mlp_2layer),\n",
    "    #(\"mlp_3layer\", model_mlp_3layer),\n",
    "    (\"mlp_4layer\", model_mlp_4layer),\n",
    "    #(\"mlp_5layer\", model_mlp_5layer),\n",
    "    #(\"mlp_6layer\", model_mlp_6layer),\n",
    "]\n",
    "\n",
    "# Define your meta-learner (you can choose any classifier)\n",
    "meta_learner = CatBoostClassifier(random_state=1)\n",
    "\n",
    "# Create the stacking ensemble\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_learner)\n",
    "model = stacking_model\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=1)\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "print('f1_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "print('precision_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
    "print('recall_macro: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(model, X, y, scoring=kappa_scorer, cv=cv, n_jobs=-1)\n",
    "print('kappa_scorer: %.4f (%.4f)' % (mean(scores), std(scores)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "JOsRCVXrtUkH",
    "WLEvQOp5tT5O",
    "WmncurFTuN2U"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
